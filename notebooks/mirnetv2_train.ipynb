{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumik12345/mirnetv2/blob/main/notebooks/mirnetv2_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq --upgrade wandb\n",
        "!pip install -qq transformers tensorflow_addons"
      ],
      "metadata": {
        "id": "knjF-7E0fwGj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jJOfJF8bfWLG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from functools import partial\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from transformers.tf_utils import shape_list\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mD_mvGQ5fWLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "7cf81529-f6a5-45de-b051-d7073df9970a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m19soumik-rakshit96\u001b[0m (\u001b[33mml-colabs\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221030_024830-25s0uwcb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ml-colabs/mirnet-v2/runs/25s0uwcb\" target=\"_blank\">headless-ghost-20</a></strong> to <a href=\"https://wandb.ai/ml-colabs/mirnet-v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact new_dataset:v0, 331.95MB. 1003 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1003 of 1003 files downloaded.  \n",
            "Done. 0:0:0.2\n"
          ]
        }
      ],
      "source": [
        "wandb.init(project=\"mirnet-v2\", entity=\"ml-colabs\", job_type=\"train\")\n",
        "config = wandb.config\n",
        "\n",
        "config.seed = 42\n",
        "random.seed(config.seed)\n",
        "tf.random.set_seed(config.seed)\n",
        "\n",
        "config.artifact_address = 'ml-colabs/mirnet-v2/new_dataset:v0'\n",
        "config.image_size = 128\n",
        "config.max_train_images = 400\n",
        "config.batch_size = 4\n",
        "config.initial_learning_rate = 2e-4\n",
        "config.minimum_learning_rate = 1e-6\n",
        "config.epochs = 300\n",
        "\n",
        "artifact = wandb.use_artifact(config.artifact_address, type='dataset')\n",
        "dataset_dir = artifact.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_C7Q51N5fWLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913f3974-ac4e-41d4-bfab-dabc38da25b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset: (400, 400)\n",
            "Validation Dataset: (85, 85)\n",
            "Test Dataset: (15, 15)\n"
          ]
        }
      ],
      "source": [
        "TRAIN_LOW_LIGHT_IMAGES = sorted(\n",
        "    glob(os.path.join(dataset_dir, \"our485/low/*\"))\n",
        ")[:config.max_train_images]\n",
        "TRAIN_GROUND_TRUTH_IMAGES = sorted(\n",
        "    glob(os.path.join(dataset_dir, \"our485/high/*\"))\n",
        ")[:config.max_train_images]\n",
        "\n",
        "VAL_LOW_LIGHT_IMAGES = sorted(\n",
        "    glob(os.path.join(dataset_dir, \"our485/low/*\"))\n",
        ")[config.max_train_images:]\n",
        "VAL_GROUND_TRUTH_IMAGES = sorted(\n",
        "    glob(os.path.join(dataset_dir, \"our485/high/*\"))\n",
        ")[config.max_train_images:]\n",
        "\n",
        "TEST_LOW_LIGHT_IMAGES = sorted(\n",
        "    glob(os.path.join(dataset_dir, \"eval15/low/*\"))\n",
        ")\n",
        "TEST_GROUND_TRUTH_IMAGES = sorted(\n",
        "    glob(os.path.join(dataset_dir, \"eval15/high/*\"))\n",
        ")\n",
        "\n",
        "print(f\"Train Dataset: ({len(TRAIN_LOW_LIGHT_IMAGES)}, {len(TRAIN_GROUND_TRUTH_IMAGES)})\")\n",
        "print(f\"Validation Dataset: ({len(VAL_LOW_LIGHT_IMAGES)}, {len(VAL_GROUND_TRUTH_IMAGES)})\")\n",
        "print(f\"Test Dataset: ({len(TEST_LOW_LIGHT_IMAGES)}, {len(TEST_GROUND_TRUTH_IMAGES)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5BPeArWPfWLL"
      },
      "outputs": [],
      "source": [
        "def read_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.cast(image, dtype=tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "\n",
        "def random_crop(low_image, gt_image):\n",
        "    low_image_shape = tf.shape(low_image)[:2]\n",
        "    crop_width = tf.random.uniform(\n",
        "        shape=(), maxval=low_image_shape[1] - config.image_size + 1, dtype=tf.int32\n",
        "    )\n",
        "    crop_height = tf.random.uniform(\n",
        "        shape=(), maxval=low_image_shape[0] - config.image_size + 1, dtype=tf.int32\n",
        "    )\n",
        "    low_image_cropped = low_image[\n",
        "        crop_height : crop_height + config.image_size,\n",
        "        crop_width : crop_width + config.image_size\n",
        "    ]\n",
        "    gt_image_cropped = gt_image[\n",
        "        crop_height : crop_height + config.image_size,\n",
        "        crop_width : crop_width + config.image_size\n",
        "    ]\n",
        "    low_image_cropped.set_shape([config.image_size, config.image_size, 3])\n",
        "    gt_image_cropped.set_shape([config.image_size, config.image_size, 3])\n",
        "    return low_image_cropped, gt_image_cropped\n",
        "\n",
        "\n",
        "def resize_images(low_image, gt_image):\n",
        "    low_image = tf.image.resize(low_image, size=[config.image_size, config.image_size])\n",
        "    gt_image = tf.image.resize(gt_image, size=[config.image_size, config.image_size])\n",
        "    low_image.set_shape([config.image_size, config.image_size, 3])\n",
        "    gt_image.set_shape([config.image_size, config.image_size, 3])\n",
        "    return low_image, gt_image\n",
        "\n",
        "\n",
        "def load_data(low_light_image_path, enhanced_image_path, apply_resize):\n",
        "    low_light_image = read_image(low_light_image_path)\n",
        "    enhanced_image = read_image(enhanced_image_path)\n",
        "    low_light_image, enhanced_image = (\n",
        "        resize_images(low_light_image, enhanced_image) if apply_resize\n",
        "        else random_crop(low_light_image, enhanced_image)\n",
        "    )\n",
        "    return low_light_image, enhanced_image\n",
        "\n",
        "\n",
        "def get_dataset(low_light_images, enhanced_images, apply_resize):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((low_light_images, enhanced_images))\n",
        "    dataset = dataset.map(\n",
        "        partial(load_data, apply_resize=apply_resize),\n",
        "        num_parallel_calls=AUTOTUNE\n",
        "    )\n",
        "    dataset = dataset.batch(config.batch_size, drop_remainder=True)\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "whnyVmWIfWLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcab121-8240-48f3-a4ef-856533692a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset: (TensorSpec(shape=(4, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(4, 128, 128, 3), dtype=tf.float32, name=None))\n",
            "Validation Dataset: (TensorSpec(shape=(4, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(4, 128, 128, 3), dtype=tf.float32, name=None))\n"
          ]
        }
      ],
      "source": [
        "train_dataset = get_dataset(TRAIN_LOW_LIGHT_IMAGES, TRAIN_GROUND_TRUTH_IMAGES, apply_resize=False)\n",
        "val_dataset = get_dataset(VAL_LOW_LIGHT_IMAGES, VAL_GROUND_TRUTH_IMAGES, apply_resize=True)\n",
        "\n",
        "print(\"Train Dataset:\", train_dataset.element_spec)\n",
        "print(\"Validation Dataset:\", val_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqWny_wrfWLM"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAAwdPwFfWLN"
      },
      "source": [
        "### SKFF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EN0zdBM0fWLO"
      },
      "outputs": [],
      "source": [
        "class SelectiveKernelFeatureFusion(tf.keras.layers.Layer):\n",
        "    def __init__(self, channels: int, *args, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.hidden_channels = max(int(channels / 8), 4)\n",
        "\n",
        "        self.average_pooling = tfa.layers.AdaptiveAveragePooling2D(output_size=1)\n",
        "\n",
        "        self.conv_channel_downscale = tf.keras.layers.Conv2D(\n",
        "            self.hidden_channels, kernel_size=1, padding=\"same\"\n",
        "        )\n",
        "        self.conv_attention_1 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=1, strides=1, padding=\"same\"\n",
        "        )\n",
        "        self.conv_attention_2 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=1, strides=1, padding=\"same\"\n",
        "        )\n",
        "\n",
        "        self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "        self.sorftmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(self, inputs, *args, **kwargs):\n",
        "        combined_input_features = inputs[0] + inputs[1]\n",
        "        channel_wise_statistics = self.average_pooling(combined_input_features)\n",
        "        downscaled_channel_wise_statistics = self.conv_channel_downscale(\n",
        "            channel_wise_statistics\n",
        "        )\n",
        "        attention_vector_1 = self.sorftmax(\n",
        "            self.conv_attention_1(downscaled_channel_wise_statistics)\n",
        "        )\n",
        "        attention_vector_2 = self.sorftmax(\n",
        "            self.conv_attention_2(downscaled_channel_wise_statistics)\n",
        "        )\n",
        "        selected_features = (\n",
        "            inputs[0] * attention_vector_1 + inputs[1] * attention_vector_2\n",
        "        )\n",
        "        return selected_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flxnl3jWfWLO"
      },
      "source": [
        "### RCB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hezl9JiefWLP"
      },
      "outputs": [],
      "source": [
        "class ContextBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, channels: int, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.mask_conv = tf.keras.layers.Conv2D(\n",
        "            1, kernel_size=1, padding=\"same\"\n",
        "        )\n",
        "\n",
        "        self.channel_add_conv_1 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=1, padding=\"same\"\n",
        "        )\n",
        "        self.channel_add_conv_2 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=1, padding=\"same\"\n",
        "        )\n",
        "\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=1)\n",
        "        self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    def modeling(self, inputs):\n",
        "        _, height, width, channels = shape_list(inputs)\n",
        "        reshaped_inputs = tf.expand_dims(\n",
        "            tf.reshape(inputs, (-1, channels, height * width)), axis=1\n",
        "        )\n",
        "\n",
        "        context_mask = self.mask_conv(inputs)\n",
        "        context_mask = tf.reshape(context_mask, (-1, height * width, 1))\n",
        "        context_mask = self.softmax(context_mask)\n",
        "        context_mask = tf.expand_dims(context_mask, axis=1)\n",
        "\n",
        "        context = tf.reshape(\n",
        "            tf.matmul(reshaped_inputs, context_mask), (-1, 1, 1, channels)\n",
        "        )\n",
        "        return context\n",
        "\n",
        "    def call(self, inputs, *args, **kwargs):\n",
        "        context = self.modeling(inputs)\n",
        "        channel_add_term = self.channel_add_conv_1(context)\n",
        "        channel_add_term = self.leaky_relu(channel_add_term)\n",
        "        channel_add_term = self.channel_add_conv_2(channel_add_term)\n",
        "        return inputs + channel_add_term\n",
        "\n",
        "\n",
        "class ResidualContextBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, channels: int, groups: int, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=3, padding=\"same\", groups=groups\n",
        "        )\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=3, padding=\"same\", groups=groups\n",
        "        )\n",
        "        self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "        self.context_block = ContextBlock(channels=channels)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.context_block(x)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = x + inputs\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPFZ1WwLfWLQ"
      },
      "source": [
        "### Downsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "glHvQ0X5fWLQ"
      },
      "outputs": [],
      "source": [
        "class DownBlock(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, channels: int, channel_factor: float, *args, **kwargs\n",
        "    ):\n",
        "        super(DownBlock, self).__init__(*args, **kwargs)\n",
        "        self.average_pool = tf.keras.layers.AveragePooling2D(\n",
        "            pool_size=2, strides=2\n",
        "        )\n",
        "        self.conv = tf.keras.layers.Conv2D(\n",
        "            int(channels * channel_factor),\n",
        "            kernel_size=1,\n",
        "            strides=1,\n",
        "            padding=\"same\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, *args, **kwargs):\n",
        "        return self.conv(self.average_pool(inputs))\n",
        "\n",
        "\n",
        "class DownSampleBlock(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels: int,\n",
        "        scale_factor: int,\n",
        "        channel_factor: float,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(DownSampleBlock, self).__init__(*args, **kwargs)\n",
        "        self.layers = []\n",
        "        for _ in range(int(np.log2(scale_factor))):\n",
        "            self.layers.append(DownBlock(channels, channel_factor))\n",
        "            channels = int(channels * channel_factor)\n",
        "\n",
        "    def call(self, x, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lOsWsjwfWLQ"
      },
      "source": [
        "### Upsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NaGNPUoqfWLR"
      },
      "outputs": [],
      "source": [
        "class UpBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, channels: int, channel_factor: float, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.conv = tf.keras.layers.Conv2D(\n",
        "            int(channels // channel_factor), kernel_size=1, strides=1, padding=\"same\"\n",
        "        )\n",
        "        self.upsample = tf.keras.layers.UpSampling2D(size=2, interpolation=\"bilinear\")\n",
        "\n",
        "    def call(self, inputs, *args, **kwargs):\n",
        "        return self.upsample(self.conv(inputs))\n",
        "\n",
        "\n",
        "class UpSampleBlock(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, channels: int, scale_factor: int, channel_factor: float, *args, **kwargs\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.layers = []\n",
        "        for _ in range(int(np.log2(scale_factor))):\n",
        "            self.layers.append(UpBlock(channels, channel_factor))\n",
        "            channels = int(channels // channel_factor)\n",
        "\n",
        "    def call(self, x, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx7kPtDDfWLR"
      },
      "source": [
        "### MRB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mERT8YFFfWLS"
      },
      "outputs": [],
      "source": [
        "class MultiScaleResidualBlock(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels: int,\n",
        "        channel_factor: float,\n",
        "        groups: int,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        # Residual Context Blocks\n",
        "        self.rcb_top = ResidualContextBlock(\n",
        "            int(channels * channel_factor**0), groups=groups\n",
        "        )\n",
        "        self.rcb_middle = ResidualContextBlock(\n",
        "            int(channels * channel_factor**1), groups=groups\n",
        "        )\n",
        "        self.rcb_bottom = ResidualContextBlock(\n",
        "            int(channels * channel_factor**2), groups=groups\n",
        "        )\n",
        "\n",
        "        # Downsample Blocks\n",
        "        self.down_2 = DownSampleBlock(\n",
        "            channels=int((channel_factor**0) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.down_4_1 = DownSampleBlock(\n",
        "            channels=int((channel_factor ** 0) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.down_4_2 = DownSampleBlock(\n",
        "            channels=int((channel_factor ** 1) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "\n",
        "        # UpSample Blocks\n",
        "        self.up21_1 = UpSampleBlock(\n",
        "            channels=int((channel_factor ** 1) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.up21_2 = UpSampleBlock(\n",
        "            channels=int((channel_factor ** 1) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.up32_1 = UpSampleBlock(\n",
        "            channels=int((channel_factor ** 2) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.up32_2 = UpSampleBlock(\n",
        "            channels=int((channel_factor ** 2) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "\n",
        "        # SKFF Blocks\n",
        "        self.skff_top = SelectiveKernelFeatureFusion(\n",
        "            channels=int(channels * channel_factor**0)\n",
        "        )\n",
        "        self.skff_middle = SelectiveKernelFeatureFusion(\n",
        "            channels=int(channels * channel_factor**1)\n",
        "        )\n",
        "\n",
        "        # Convolution\n",
        "        self.conv_out = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=1, padding=\"same\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, *args, **kwargs):\n",
        "        x_top = inputs\n",
        "        x_middle = self.down_2(x_top)\n",
        "        x_bottom = self.down_4_2(self.down_4_1(x_top))\n",
        "\n",
        "        x_top = self.rcb_top(x_top)\n",
        "        x_middle = self.rcb_middle(x_middle)\n",
        "        x_bottom = self.rcb_bottom(x_bottom)\n",
        "\n",
        "        x_middle = self.skff_middle([x_middle, self.up32_1(x_bottom)])\n",
        "        x_top = self.skff_top([x_top, self.up21_1(x_middle)])\n",
        "\n",
        "        x_top = self.rcb_top(x_top)\n",
        "        x_middle = self.rcb_middle(x_middle)\n",
        "        x_bottom = self.rcb_bottom(x_bottom)\n",
        "\n",
        "        x_middle = self.skff_middle([x_middle, self.up32_2(x_bottom)])\n",
        "        x_top = self.skff_top([x_top, self.up21_2(x_middle)])\n",
        "\n",
        "        output = self.conv_out(x_top)\n",
        "        output = output + inputs\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEkc29N9fWLS"
      },
      "source": [
        "### RRG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WuvJK-mWfWLS"
      },
      "outputs": [],
      "source": [
        "class RecursiveResidualGroup(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels: int,\n",
        "        num_mrb_blocks: int,\n",
        "        channel_factor: float,\n",
        "        groups: int,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.layers = [\n",
        "            MultiScaleResidualBlock(channels, channel_factor, groups)\n",
        "            for _ in range(num_mrb_blocks)\n",
        "        ]\n",
        "        self.layers.append(\n",
        "            tf.keras.layers.Conv2D(\n",
        "                channels, kernel_size=3, strides=1, padding=\"same\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, *args, **kwargs):\n",
        "        residual = inputs\n",
        "        for layer in self.layers:\n",
        "            residual = layer(residual)\n",
        "        residual = residual + inputs\n",
        "        return residual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRy2kgy1fWLT"
      },
      "source": [
        "### MirNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OsA-k1IMfWLT"
      },
      "outputs": [],
      "source": [
        "class MirNetv2(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels: int,\n",
        "        channel_factor: float,\n",
        "        num_mrb_blocks: int,\n",
        "        add_residual_connection: bool,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.add_residual_connection = add_residual_connection\n",
        "\n",
        "        self.conv_in = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=3, padding=\"same\"\n",
        "        )\n",
        "\n",
        "        self.rrg_block_1 = RecursiveResidualGroup(\n",
        "            channels, num_mrb_blocks, channel_factor, groups=1\n",
        "        )\n",
        "        self.rrg_block_2 = RecursiveResidualGroup(\n",
        "            channels, num_mrb_blocks, channel_factor, groups=2\n",
        "        )\n",
        "        self.rrg_block_3 = RecursiveResidualGroup(\n",
        "            channels, num_mrb_blocks, channel_factor, groups=4\n",
        "        )\n",
        "        self.rrg_block_4 = RecursiveResidualGroup(\n",
        "            channels, num_mrb_blocks, channel_factor, groups=4\n",
        "        )\n",
        "\n",
        "        self.conv_out = tf.keras.layers.Conv2D(\n",
        "            3, kernel_size=3, padding=\"same\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        shallow_features = self.conv_in(inputs)\n",
        "        deep_features = self.rrg_block_1(shallow_features)\n",
        "        deep_features = self.rrg_block_2(deep_features)\n",
        "        deep_features = self.rrg_block_3(deep_features)\n",
        "        deep_features = self.rrg_block_4(deep_features)\n",
        "        output = self.conv_out(deep_features)\n",
        "        output = output + inputs if self.add_residual_connection else output\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FwOXheGVfWLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e591803-031c-458b-f4d7-6d8a28246f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Conv._jit_compiled_convolution_op at 0x7f7f5b7fadd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Conv._jit_compiled_convolution_op at 0x7f7f52a70710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mir_netv2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             multiple                  2240      \n",
            "                                                                 \n",
            " recursive_residual_group (R  multiple                 2426936   \n",
            " ecursiveResidualGroup)                                          \n",
            "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
            "| multi_scale_residual_block   multiple               1184628   |\n",
            "| (MultiScaleResidualBlock)                                     |\n",
            "|                                                               |\n",
            "| multi_scale_residual_block_  multiple               1184628   |\n",
            "| 1 (MultiScaleResidualBlock)                                   |\n",
            "|                                                               |\n",
            "| conv2d_59 (Conv2D)        multiple                  57680     |\n",
            "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
            " recursive_residual_group_1   multiple                 1469336   \n",
            " (RecursiveResidualGroup)                                        \n",
            "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
            "| multi_scale_residual_block_  multiple               705828    |\n",
            "| 2 (MultiScaleResidualBlock)                                   |\n",
            "|                                                               |\n",
            "| multi_scale_residual_block_  multiple               705828    |\n",
            "| 3 (MultiScaleResidualBlock)                                   |\n",
            "|                                                               |\n",
            "| conv2d_118 (Conv2D)       multiple                  57680     |\n",
            "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
            " recursive_residual_group_2   multiple                 990536    \n",
            " (RecursiveResidualGroup)                                        \n",
            "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
            "| multi_scale_residual_block_  multiple               466428    |\n",
            "| 4 (MultiScaleResidualBlock)                                   |\n",
            "|                                                               |\n",
            "| multi_scale_residual_block_  multiple               466428    |\n",
            "| 5 (MultiScaleResidualBlock)                                   |\n",
            "|                                                               |\n",
            "| conv2d_177 (Conv2D)       multiple                  57680     |\n",
            "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
            " recursive_residual_group_3   multiple                 990536    \n",
            " (RecursiveResidualGroup)                                        \n",
            "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
            "| multi_scale_residual_block_  multiple               466428    |\n",
            "| 6 (MultiScaleResidualBlock)                                   |\n",
            "|                                                               |\n",
            "| multi_scale_residual_block_  multiple               466428    |\n",
            "| 7 (MultiScaleResidualBlock)                                   |\n",
            "|                                                               |\n",
            "| conv2d_236 (Conv2D)       multiple                  57680     |\n",
            "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
            " conv2d_237 (Conv2D)         multiple                  2163      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,881,747\n",
            "Trainable params: 5,881,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Input Shape: (1, 128, 128, 3)\n",
            "Output Shape: (1, 128, 128, 3)\n"
          ]
        }
      ],
      "source": [
        "model = MirNetv2(\n",
        "    channels=80,\n",
        "    channel_factor=1.5,\n",
        "    num_mrb_blocks=2,\n",
        "    add_residual_connection=True\n",
        ")\n",
        "\n",
        "dummy_inputs = tf.ones((1, config.image_size, config.image_size, 3))\n",
        "dummy_outputs = model(dummy_inputs)\n",
        "model.summary(expand_nested=True)\n",
        "print(\"\\nInput Shape:\", dummy_inputs.shape)\n",
        "print(\"Output Shape:\", dummy_outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyKiE1TTfWLU"
      },
      "source": [
        "## Losses and Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fhCfKW2QfWLV"
      },
      "outputs": [],
      "source": [
        "class CharbonnierLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, epsilon: float, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.epsilon = tf.convert_to_tensor(epsilon)\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        squared_difference = tf.square(y_true - y_pred)\n",
        "        return tf.reduce_mean(\n",
        "            tf.sqrt(squared_difference + tf.square(self.epsilon))\n",
        "        )\n",
        "\n",
        "\n",
        "class PSNRMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, max_val: float, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.max_val = max_val\n",
        "        self.psnr = tf.keras.metrics.Mean(name=\"psnr\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, *args, **kwargs):\n",
        "        psnr = tf.image.psnr(y_true, y_pred, max_val=self.max_val)\n",
        "        self.psnr.update_state(psnr, *args, **kwargs)\n",
        "\n",
        "    def result(self):\n",
        "        return self.psnr.result()\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.psnr.reset_state()\n",
        "\n",
        "\n",
        "class SSIMMetric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, max_val: float, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.max_val = max_val\n",
        "        self.ssim = tf.keras.metrics.Mean(name=\"ssim\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, *args, **kwargs):\n",
        "        ssim = tf.image.ssim(y_true, y_pred, max_val=self.max_val)\n",
        "        self.ssim.update_state(ssim, *args, **kwargs)\n",
        "\n",
        "    def result(self):\n",
        "        return self.ssim.result()\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.ssim.reset_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oepNCM1sfWLW"
      },
      "outputs": [],
      "source": [
        "loss = CharbonnierLoss(epsilon=1e-3)\n",
        "\n",
        "psnr_metric = PSNRMetric(max_val=1.0)\n",
        "ssim_metric = SSIMMetric(max_val=1.0)\n",
        "\n",
        "decay_steps = (config.max_train_images // config.batch_size) * config.epochs\n",
        "lr_schedule_fn = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=config.initial_learning_rate,\n",
        "    decay_steps=decay_steps,\n",
        "    alpha=config.minimum_learning_rate,\n",
        ")\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=lr_schedule_fn, beta_1=0.9, beta_2=0.999,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer, loss=loss, metrics=[psnr_metric, ssim_metric]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiFrSB-pfWLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be49f8a-e1b1-4967-ebbb-1c678421941e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1717 - psnr_metric: 15.0998 - ssim_metric: 0.6540"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b6c8a10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b6d66d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b6372d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b641190>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b5d0890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b5db690>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b540390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b54a210>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b4bac50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5b4c6ad0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5343fbd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f534518d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f5343c1d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f533c7050>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f533b0050>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7f7f533bbf10>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, multi_scale_residual_block_layer_call_fn, multi_scale_residual_block_layer_call_and_return_conditional_losses, multi_scale_residual_block_1_layer_call_fn while saving (showing 5 of 1250). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model)... Done. 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 170s 1s/step - loss: 0.1717 - psnr_metric: 15.0998 - ssim_metric: 0.6540 - val_loss: 0.1208 - val_psnr_metric: 17.9959 - val_ssim_metric: 0.7309\n",
            "Epoch 2/300\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1668 - psnr_metric: 15.6472 - ssim_metric: 0.6784"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model)... Done. 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 71s 710ms/step - loss: 0.1668 - psnr_metric: 15.6472 - ssim_metric: 0.6784 - val_loss: 0.1334 - val_psnr_metric: 16.4894 - val_ssim_metric: 0.7476\n",
            "Epoch 3/300\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.1632 - psnr_metric: 15.6207 - ssim_metric: 0.6833"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model)... Done. 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 70s 700ms/step - loss: 0.1632 - psnr_metric: 15.6207 - ssim_metric: 0.6833 - val_loss: 0.1391 - val_psnr_metric: 16.6426 - val_ssim_metric: 0.7486\n",
            "Epoch 4/300\n",
            " 56/100 [===============>..............] - ETA: 28s - loss: 0.1730 - psnr_metric: 15.1493 - ssim_metric: 0.6616"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    WandbMetricsLogger(),\n",
        "    WandbModelCheckpoint(filepath=\"model\", save_best_only=True)\n",
        "]\n",
        "\n",
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=config.epochs,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "7G7hBMuXhDN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WTQrzEvxwcyO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}