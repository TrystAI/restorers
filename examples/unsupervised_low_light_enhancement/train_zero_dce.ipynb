{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from absl import app, flags, logging\n",
    "from ml_collections.config_flags import config_flags\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "\n",
    "import wandb\n",
    "\n",
    "from low_light_config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project_name = 'zero-dce' #@param {type:\"string\"}\n",
    "wandb_run_name = 'train/lot' #@param {type:\"string\"}\n",
    "wandb_entity_name = 'ml-colabs' #@param {type:\"string\"}\n",
    "wandb_job_type = 'test' #@param {type:\"string\"}\n",
    "\n",
    "experiment_configs = get_config()\n",
    "wandb.init(\n",
    "    project=wandb_project_name,\n",
    "    name=wandb_run_name,\n",
    "    entity=wandb_entity_name,\n",
    "    job_type=wandb_job_type,\n",
    "    config=experiment_configs.to_dict(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(experiment_configs.seed)\n",
    "strategy = initialize_device()\n",
    "batch_size = (\n",
    "    experiment_configs.data_loader_configs.local_batch_size\n",
    "    * strategy.num_replicas_in_sync\n",
    ")\n",
    "wandb.config.global_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(\n",
    "        images=image,\n",
    "        size=[\n",
    "            config.data_loader_configs.image_size,\n",
    "            config.data_loader_configs.image_size\n",
    "        ]\n",
    "    )\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def data_generator(low_light_images):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((low_light_images))\n",
    "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "artifact = run.use_artifact(\n",
    "    config.data_loader_configs.dataset_artifact_address, type='dataset'\n",
    ")\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "train_low_light_images = sorted(glob(os.path.join(artifact_dir, \"our485\", \"low\", \"*\")))\n",
    "num_train_images = int((1 - config.data_loader_configs.val_split) * len(train_low_light_images))\n",
    "val_low_light_images = train_low_light_images[num_train_images:]\n",
    "train_low_light_images = train_low_light_images[:num_train_images]\n",
    "\n",
    "train_dataset = data_generator(train_low_light_images)\n",
    "val_dataset = data_generator(val_low_light_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16 (default, Jan 10 2023, 15:23:34) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
