{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404fd8b-9845-462f-b4fc-92217360383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from low_light_config import get_config\n",
    "from restorers.model.zero_dce import ZeroDCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04cc65-f500-4423-8d5e-f0b27e44fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project_name = 'zero-dce' #@param {type:\"string\"}\n",
    "wandb_run_name = 'train/lol' #@param {type:\"string\"}\n",
    "wandb_entity_name = 'ml-colabs' #@param {type:\"string\"}\n",
    "wandb_job_type = 'test' #@param {type:\"string\"}\n",
    "\n",
    "experiment_configs = get_config()\n",
    "wandb.init(\n",
    "    project=wandb_project_name,\n",
    "    name=wandb_run_name,\n",
    "    entity=wandb_entity_name,\n",
    "    job_type=wandb_job_type,\n",
    "    config=experiment_configs.to_dict(),\n",
    ")\n",
    "\n",
    "config = wandb.config\n",
    "config.model_artifact_address = \"ml-colabs/zero-dce/run_55hfxg0a_model:v9\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c95dd2a-deef-44c2-9fa0-767d92ef0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = wandb.use_artifact(config.model_artifact_address, type=\"model\")\n",
    "model_configs = artifact.logged_by().config[\"model_configs\"]\n",
    "model_path = artifact.download()\n",
    "\n",
    "# Load Model\n",
    "model = tf.keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0500fba-32cf-4da5-a05e-505b93c49d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_artifact_address = \"ml-colabs/dataset/LoL:v0\"\n",
    "\n",
    "# Fetch dataset from WandB dataset artifact\n",
    "artifact = wandb.use_artifact(dataset_artifact_address, type='dataset')\n",
    "dataset_dir = artifact.download()\n",
    "\n",
    "train_val_low_light_images = sorted(glob(\n",
    "    os.path.join(dataset_dir, \"our485\", \"low\", \"*.png\")\n",
    "))\n",
    "train_val_ground_truth_images = sorted(glob(\n",
    "    os.path.join(dataset_dir, \"our485\", \"high\", \"*.png\")\n",
    "))\n",
    "\n",
    "test_low_light_images = sorted(glob(\n",
    "    os.path.join(dataset_dir, \"eval15\", \"low\", \"*.png\")\n",
    "))\n",
    "test_ground_truth_images = sorted(glob(\n",
    "    os.path.join(dataset_dir, \"eval15\", \"high\", \"*.png\")\n",
    "))\n",
    "\n",
    "print(\n",
    "    \"Number of low-light images for training and validation:\",\n",
    "    len(test_low_light_images)\n",
    ")\n",
    "print(\n",
    "    \"Number of ground-truth images for training and validation:\",\n",
    "    len(test_ground_truth_images)\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Number of low-light images for evaluation:\",\n",
    "    len(test_low_light_images)\n",
    ")\n",
    "print(\n",
    "    \"Number of ground-truth images for evaluation:\",\n",
    "    len(test_ground_truth_images)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e88427-553c-4d3b-80b6-1234c471f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocesses the image for inference.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (1, height, width, 3) preprocessed for inference.\n",
    "    \"\"\"\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = image.astype(\"float32\") / 255.0\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "\n",
    "def postprocess_image(model_output):\n",
    "    \"\"\"Postprocesses the model output for inference.\n",
    "    \n",
    "    Returns:\n",
    "        A list of PIL.Image.Image objects postprocessed for visualization.\n",
    "    \"\"\"\n",
    "    model_output = model_output * 255.0\n",
    "    model_output = model_output.clip(0, 255)\n",
    "    image = model_output[0].reshape(\n",
    "        (np.shape(model_output)[1], np.shape(model_output)[2], 3)\n",
    "    )\n",
    "    return Image.fromarray(np.uint8(image))\n",
    "\n",
    "\n",
    "def plot_results(images, titles, figure_size=(12, 12)):\n",
    "    \"\"\"A simple utility for plotting the results\"\"\"\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    for i in range(len(images)):\n",
    "        fig.add_subplot(1, len(images), i + 1).set_title(titles[i])\n",
    "        _ = plt.imshow(images[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def infer_and_visualize(\n",
    "    low_light_image_file,\n",
    "    ground_truth_image_file,\n",
    "    model,\n",
    "    visualize_plots\n",
    "):\n",
    "    low_light_image = Image.open(low_light_image_file)\n",
    "    ground_truth_image = Image.open(ground_truth_image_file)\n",
    "    preprocessed_image = preprocess_image(low_light_image)\n",
    "    start = time()\n",
    "    preprocessed_ground_truth = preprocess_image(ground_truth_image)\n",
    "    inference_time = time() - start\n",
    "    model_output = model.predict(preprocessed_image, verbose=0)\n",
    "    psnr = tf.image.psnr(preprocessed_image, model_output, max_val=1.0)\n",
    "    ssim = tf.image.ssim(preprocessed_image, model_output, max_val=1.0)\n",
    "    post_processed_image = postprocess_image(model_output)\n",
    "    \n",
    "    if visualize_plots:\n",
    "        plot_results(\n",
    "            images=[\n",
    "                low_light_image, ground_truth_image, post_processed_image\n",
    "            ],\n",
    "            titles=[\n",
    "                \"Low-light Image\", \"Ground-truth Image\", \"Predicted Image\"\n",
    "            ],\n",
    "            figure_size=(22, 15)\n",
    "        )\n",
    "    return (\n",
    "        low_light_image,\n",
    "        ground_truth_image,\n",
    "        post_processed_image,\n",
    "        psnr, ssim, inference_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e9281-fcf7-47fa-af81-fd68a0213e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=[\n",
    "    \"Input-Image\",\n",
    "    \"Ground-Truth\",\n",
    "    \"Image-Enhanced-By-AutoContrast\",\n",
    "    \"Image-Enhanced-By-ZeroDCE\",\n",
    "    \"Peak-Signal-Noise-Ratio\",\n",
    "    \"Structual-Similarity\",\n",
    "    \"Inference-Time\",\n",
    "    \"Dataset\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdedd83d-7419-4be6-a1a3-c3c5b82de277",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(range(len(train_val_low_light_images))):\n",
    "    (\n",
    "        low_light_image,\n",
    "        ground_truth_image,\n",
    "        mirnet_enhanced_image,\n",
    "        psnr, ssim, inference_time\n",
    "    ) = infer_and_visualize(\n",
    "        train_val_low_light_images[idx],\n",
    "        train_val_ground_truth_images[idx],\n",
    "        model,\n",
    "        visualize_plots=False\n",
    "    )\n",
    "    autocontrast_enhanced_image = ImageOps.autocontrast(low_light_image)\n",
    "    table.add_data(\n",
    "        wandb.Image(low_light_image),\n",
    "        wandb.Image(ground_truth_image),\n",
    "        wandb.Image(autocontrast_enhanced_image),\n",
    "        wandb.Image(mirnet_enhanced_image),\n",
    "        psnr.numpy().item(), ssim.numpy().item(),\n",
    "        inference_time, \"LoL/Trian-Val\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2a0c1-b811-4f06-9f7b-c7a4774831ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(range(len(test_low_light_images))):\n",
    "    (\n",
    "        low_light_image,\n",
    "        ground_truth_image,\n",
    "        mirnet_enhanced_image,\n",
    "        psnr, ssim, inference_time\n",
    "    ) = infer_and_visualize(\n",
    "        test_low_light_images[idx],\n",
    "        test_ground_truth_images[idx],\n",
    "        model,\n",
    "        visualize_plots=False\n",
    "    )\n",
    "    autocontrast_enhanced_image = ImageOps.autocontrast(low_light_image)\n",
    "    table.add_data(\n",
    "        wandb.Image(low_light_image),\n",
    "        wandb.Image(ground_truth_image),\n",
    "        wandb.Image(autocontrast_enhanced_image),\n",
    "        wandb.Image(mirnet_enhanced_image),\n",
    "        psnr.numpy().item(), ssim.numpy().item(),\n",
    "        inference_time, \"LoL/Eval15\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d01af-fd35-478f-89f6-9c908862730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"Evaluation\": table})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
