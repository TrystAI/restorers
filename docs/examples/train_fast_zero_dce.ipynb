{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/keras/restorers/Train_Zero_DCE_Restorers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{restorers-zero-dce-train} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåà Restorers + WandB ü™Ñüêù\n",
    "\n",
    "<!--- @wandbcode{restorers-mirnetv2-train} -->\n",
    "\n",
    "This notebook shows how to train a [Zero-DCE](https://arxiv.org/abs/2001.06826) model for zero-reference low-light enhancement using [**restorers**](https://github.com/soumik12345/restorers) and [**wandb**](https://wandb.ai/site). For more details regarding usage of restorers, refer to the following report:\n",
    "\n",
    "[![](https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-gradient.svg)](https://wandb.ai/ml-colabs/low-light-enhancement/reports/Lighting-up-Images-in-the-Deep-Learning-Era--VmlldzozNzE4Njkz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip setuptools\n",
    "!pip install git+https://github.com/soumik12345/restorers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import wandb\n",
    "# import the wandb callbacks for keras\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "from restorers.dataloader import UnsupervisedLOLDataLoader\n",
    "from restorers.model.zero_dce import ZeroDCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"low-light-enhancement\", job_type=\"train\")\n",
    "\n",
    "\n",
    "data_loader = UnsupervisedLOLDataLoader(\n",
    "    # size of image crops on which we will train\n",
    "    image_size=128,\n",
    "    # bit depth of the images\n",
    "    bit_depth=8,\n",
    "    # fraction of images for validation\n",
    "    val_split=0.2,\n",
    "    # visualize the dataset on WandB or not\n",
    "    visualize_on_wandb=True,\n",
    "    # the wandb artifact address of the dataset,\n",
    "    # this can be found from the `Usage` tab of\n",
    "    # the aforemenioned weave panel\n",
    "    dataset_artifact_address=\"ml-colabs/dataset/LoL:v0\",\n",
    ")\n",
    "\n",
    "# call `get_datasets` on the `data_loader` to get\n",
    "# the TensorFlow datasets corresponding to the \n",
    "# training and validation splits\n",
    "train_dataset, val_dataset = data_loader.get_datasets(batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# define the ZeroDCE model; this gives us a `tf.keras.Model`\n",
    "model = ZeroDCE(\n",
    "    num_intermediate_filters=32, # number of filters in the intermediate convolutional layers\n",
    "    num_iterations=8, # number of iterations of enhancement\n",
    "    decoder_channel_factor=1 # factor by which number filters in the decoder of deep curve estimation layer is multiplied\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    weight_exposure_loss=1.0, # weight of the exposure control loss\n",
    "    weight_color_constancy_loss=0.5, # weight of the color constancy loss\n",
    "    weight_illumination_smoothness_loss=20, # weight of the illumination smoothness loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # define the metrics logger callback;\n",
    "    # we set the `log_freq=\"batch\"` explicitly\n",
    "    # to the metrics are logged both batch-wise and epoch-wise\n",
    "    WandbMetricsLogger(log_freq=\"batch\"),\n",
    "    # define the model checkpoint callback\n",
    "    WandbModelCheckpoint(\n",
    "        filepath=\"checkpoint\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=False,\n",
    "        save_weights_only=False,\n",
    "        initial_value_threshold=None,\n",
    "    )\n",
    "]\n",
    "\n",
    "# call model.fit()\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
